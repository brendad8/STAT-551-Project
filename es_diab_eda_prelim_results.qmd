---
title: "Early Stage Diabetes (EDA + Preliminary Results)"
author: "Rachel Roggenkemper"
format: html
editor: visual
---

# Set-up & Data Cleaning

```{r}
#| label: load-packages
#| message: false

library(tidyverse)
library(tidymodels)
library(rpart)
library(rpart.plot)
library(rsample)
library(themis)
library(yardstick)
```

```{r}
#| label: read-data
#| message: false

es_diab <- read_csv(here::here("data", "early_stage_diabetes.csv"))
```

```{r}
#| label: clean-response-vars

es_diab <- es_diab %>%
  mutate(target = if_else(class == "Negative", "no diabetes", "diabetes"),
         target = factor(target, levels = c("diabetes", "no diabetes"))) %>%
  select(-class)
```

```{r}
#| label: check-nas-diab_es
es_diab %>% 
  is.na() %>%
  as.data.frame() %>%
  lapply(FUN = sum) %>%
  as.data.frame()
```

```{r}
#| label: distribution of response variable 

N <- nrow(es_diab)
es_diab %>%
  select(target) %>%
  group_by(target) %>%
  summarize(n = n()) %>%
  mutate(prop = n / N)
```

# Exploratory Data Analysis

## Distribution of Target Variable

```{r}
es_diab %>%
  ggplot(aes(x = target, fill = target)) +
  geom_bar() +
  labs(title = "Distribution of Target Variable", x = "Target", y = "Count") 
```

## Age Distribution

```{r}
es_diab %>%
  ggplot(aes(x = Age, fill = target)) +
  geom_histogram(bins = 20, alpha = 0.7, position = "identity") +
  labs(title = "Age Distribution by Target", x = "Age", y = "Count")
```

## Gender versus Diabetes

```{r}
es_diab %>%
  ggplot(aes(x = Gender, fill = target)) +
  geom_bar(position = "fill") +
  labs(title = "Gender vs Diabetes", x = "Gender", y = "Proportion") 
```

## Polydipsia versus Diabetes (by Gender)

### Excessive Thirst

```{r}
es_diab %>%
  ggplot() +
  geom_bar(aes(x = Polydipsia, fill = target), position = "fill") +
  facet_wrap(~Gender) +
  labs(title = "Polydipsia vs Diabetes (by Gender)", x = "Polydipsia", y = "Proportion")
```

## Polyuria versus Diabetes (by Gender)

### Excessive Urination

```{r}
es_diab %>%
  ggplot() +
  geom_bar(aes(x = Polyuria, fill = target), position = "fill") +
  facet_wrap(~Gender) +
  labs(title = "Polyuria vs Diabetes (by Gender)", x = "Polyuria", y = "Proportion")
```

## Polyuria vs Polyuria (by Diabetes)

```{r}
es_diab %>%
  ggplot() +
  geom_jitter(aes(x = Polydipsia, y = Polyuria, color = target)) +
  facet_wrap(~target) +
  labs(title = "Polyuria vs Polyuria (by Diabetes)", x = "Polydipsia", y = "Polyuria")
```

## Sudden Weight Loss versus Diabetes by Gender

```{r}
es_diab %>%
  ggplot() +
  geom_bar(aes(x = `sudden weight loss`, fill = target), position = "fill") +
  facet_wrap(~Gender) +
  labs(title = "Sudden Weight Loss vs Diabetes (by Gender)", 
       x = "Sudden Weight Loss", 
       y = "Proportion")
```

## Weakness vs Diabetes (by Gender)

```{r}
es_diab %>%
  ggplot() +
  geom_bar(aes(x = weakness, fill = target), position = "fill") +
  facet_wrap(~Gender) +
  labs(title = "Weakness vs Diabetes (by Gender)", 
       x = "Weakness", 
       y = "Proportion")
```

## Polyphagia vs Diabetes (by Gender)

### Excessive Hunger

```{r}
es_diab %>%
  ggplot() +
  geom_bar(aes(x = Polyphagia, fill = target), position = "fill") +
  facet_wrap(~Gender) +
  labs(title = "Polyphagia vs Diabetes (by Gender)", 
       x = "Polyphagia", 
       y = "Proportion")
```

## Delayed Healing vs Diabetes (by Gender)

Not an important predictor from the plot, just shows male vs female difference

```{r}
es_diab %>%
  ggplot() +
  geom_bar(aes(x = `delayed healing`, fill = target), position = "fill") +
  facet_wrap(~Gender) +
  labs(title = "Delayed Healing vs Diabetes (by Gender)", 
       x = "Delayed Healing", 
       y = "Proportion")
```

## Obesity vs Diabetes (by Gender)

Not an important predictor from the plot (especially for women), mainly just shows male vs female difference

```{r}
es_diab %>%
  ggplot() +
  geom_bar(aes(x = Obesity, fill = target), position = "fill") +
  facet_wrap(~Gender) +
  labs(title = "Obesity vs Diabetes (by Gender)", 
       x = "Obesity", 
       y = "Proportion")
```

## Genital Thrush vs Diabetes (by Gender)

```{r}
es_diab %>%
  ggplot() +
  geom_bar(aes(x = `Genital thrush`, fill = target), position = "fill") +
  facet_wrap(~Gender) +
  labs(title = "Genital Thrush vs Diabetes (by Gender)", 
       x = "Genital Thrush", 
       y = "Proportion")
```

## Visual Blurring vs Diabetes (by Gender)

```{r}
es_diab %>%
  ggplot() +
  geom_bar(aes(x = `visual blurring`, fill = target), position = "fill") +
  facet_wrap(~Gender) +
  labs(title = "Visual Blurring vs Diabetes (by Gender)", 
       x = "Visual Blurring", 
       y = "Proportion")
```

## Partial Paresis vs Diabetes (by Gender)

### Weakness or reduced muscle strength

```{r}
es_diab %>%
  ggplot() +
  geom_bar(aes(x = `partial paresis`, fill = target), position = "fill") +
  facet_wrap(~Gender) +
  labs(title = "Partial Paresis vs Diabetes (by Gender)", 
       x = "Partial Paresis", 
       y = "Proportion")
```

## Irritability vs Diabetes (by Gender)

```{r}
es_diab %>%
  ggplot() +
  geom_bar(aes(x = Irritability, fill = target), position = "fill") +
  facet_wrap(~Gender) +
  labs(title = "Irritability vs Diabetes (by Gender)", 
       x = "Irritability", 
       y = "Proportion")
```

## Itching vs Diabetes (by Gender)

Not an important predictor from the plot, just shows male vs female difference

```{r}
es_diab %>%
  ggplot() +
  geom_bar(aes(x = Itching, fill = target), position = "fill") +
  facet_wrap(~Gender) +
  labs(title = "Itching vs Diabetes (by Gender)", 
       x = "Itching", 
       y = "Proportion")
```

## Alopecia vs Diabetes (by Gender)

```{r}
es_diab %>%
  ggplot() +
  geom_bar(aes(x = Alopecia, fill = target), position = "fill") +
  facet_wrap(~Gender) +
  labs(title = "Alopecia vs Diabetes (by Gender)", 
       x = "Alopecia", 
       y = "Proportion")
```

## Muscle Stiffness vs Diabetes (by Gender)

Not an important predictor from the plot, mainly just shows male vs female difference

```{r}
es_diab %>%
  ggplot() +
  geom_bar(aes(x = `muscle stiffness`, fill = target), position = "fill") +
  facet_wrap(~Gender) +
  labs(title = "Muscle Stiffness vs Diabetes (by Gender)", 
       x = "Muscle Stiffness", 
       y = "Proportion")
```

# Preliminary Results

## Set-Up

```{r}
#| label: cross validation
#| eval: false

es_diab_cv <- vfold_cv(es_diab, v = 10)
```

```{r}
#| label: recipes 
#| eval: false

recipe <- recipe(target ~ ., 
                   data = es_diab) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors())

recipe_tree <- recipe(target ~ ., 
                   data = es_diab) 

recipe_pca <- recipe(target ~ ., 
                   data = es_diab) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%            
  step_pca(all_predictors()) 
```

## Logistic Regression

```{r}
#| label: logistic regression 
#| eval: false

logit_mod <- logistic_reg() %>%
  set_mode("classification") %>%
  set_engine("glm")

logit_wflow <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(logit_mod)

cv_results <- fit_resamples(
  logit_wflow,
  resamples = es_diab_cv,
  metrics = metric_set(roc_auc, accuracy, precision, recall, brier_class)
)

collect_metrics(cv_results)
```

## Logistic Regression with Elastic Net

```{r}
#| label: logistic regression with elastic net
#| eval: false

elastic_net_mod <- logistic_reg(
  penalty = tune(),
  mixture = tune()
) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

elastic_net_wflow <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(elastic_net_mod)

elastic_net_grid <- grid_regular(
  penalty(range = c(0.001, 1)),
  mixture(range = c(0, 1)),
  levels = 10
)

cv_results <- tune_grid(
  elastic_net_wflow,
  resamples = es_diab_cv,
  grid = elastic_net_grid,
  metrics = metric_set(roc_auc, accuracy, precision, recall, brier_class)
)

metrics <- collect_metrics(cv_results)

metrics %>%
    filter(.metric == "roc_auc") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "accuracy") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "precision") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "recall") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "brier_class") %>%
    arrange(mean)
```

```{r}
#| eval: false

elastic_net_mod <- logistic_reg(
  penalty = 1.002305,
  mixture = 0
) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

elastic_net_wflow <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(elastic_net_mod)

elastic_net_wflow %>%
  fit_resamples(es_diab_cv, metrics = metric_set(accuracy, roc_auc, sensitivity)) %>%
  collect_metrics()

```

## Decision Tree

```{r}
#| label: decision tree
#| eval: false

tree_mod <- decision_tree(
  cost_complexity = tune(),
  tree_depth = tune()
) %>%
  set_mode("classification") %>%
  set_engine("rpart")

tree_wflow <- workflow() %>%
  add_recipe(recipe_tree) %>%
  add_model(tree_mod)

tree_grid <- grid_regular(
  cost_complexity(range = c(0.001, 0.1)),
  tree_depth(range = c(1, 20)),
  levels = 10
)

cv_results <- tune_grid(
  tree_wflow,
  resamples = es_diab_cv,
  grid = tree_grid,
  metrics = metric_set(roc_auc, accuracy, precision, recall, brier_class)
)

metrics <- collect_metrics(cv_results)

metrics %>%
    filter(.metric == "roc_auc") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "accuracy") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "precision") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "recall") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "brier_class") %>%
    arrange(mean)
```

```{r}
#| label: decision tree plot
#| eval: false

mod_dt <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

wflow_dt <- workflow() %>%
  add_recipe(recipe_tree) %>%
  add_model(mod_dt)

fit_dt <- wflow_dt %>%
  fit(es_diab)

fitted_dt <- fit_dt %>% 
  extract_fit_parsnip()

rpart.plot(fitted_dt$fit, roundint = FALSE)
```

## Random Forest

```{r}
#| label: random forest
#| eval: false

rf_mod <- rand_forest(
  mtry = tune(),
  min_n = tune(),
  trees = 100
) %>%
  set_mode("classification") %>%
  set_engine("ranger")

rf_wflow <- workflow() %>%
  add_recipe(recipe_tree) %>%
  add_model(rf_mod)

rf_grid <- grid_regular(
  mtry(range = c(1, 16)),
  min_n(range = c(2, 10)),
  levels = 10
)

cv_results <- tune_grid(
  rf_wflow,
  resamples = es_diab_cv,
  grid = rf_grid,
  metrics = metric_set(roc_auc, accuracy, precision, recall, brier_class)
)

metrics <- collect_metrics(cv_results)

metrics %>%
    filter(.metric == "roc_auc") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "accuracy") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "precision") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "recall") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "brier_class") %>%
    arrange(mean)
```

## Random Forest with PCA

```{r}
#| label: random forest with pca 
#| eval: false

rf_mod <- rand_forest(
  mtry = tune(),
  min_n = tune(),
  trees = 100
) %>%
  set_mode("classification") %>%
  set_engine("ranger")

rf_pca_wflow <- workflow() %>%
  add_recipe(recipe_pca) %>%
  add_model(rf_mod)

rf_grid <- grid_regular(
  mtry(range = c(1, 16)),
  min_n(range = c(2, 10)),
  levels = 10
)

cv_results <- tune_grid(
  rf_pca_wflow,
  resamples = es_diab_cv,
  grid = rf_grid,
  metrics = metric_set(roc_auc, accuracy, precision, recall, brier_class)
)

metrics <- collect_metrics(cv_results)

metrics %>%
    filter(.metric == "roc_auc") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "accuracy") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "precision") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "recall") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "brier_class") %>%
    arrange(mean)
```

# Analysis

```{r}
#| label: plot of gender split

es_diab %>%
  ggplot() +
  geom_bar(aes(x = "", fill = Gender), position = "fill") +
  labs(title = "Proportion of Men and Women", 
       x = NULL, 
       y = "Proportion")



gender_proportions <- es_diab %>%
  count(Gender) %>%
  mutate(Prop = n / sum(n))

ggplot(gender_proportions, aes(x = "", y = Prop, fill = Gender)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = "Proportion of Men and Women",
    x = NULL,
    y = NULL
  ) +
  theme_void() +
  theme(legend.position = "right")
```

```{r}
#| label: plot of target split

es_diab %>%
  ggplot() +
  geom_bar(aes(x = "", fill = target), position = "fill") +
  labs(title = "Proportion of Diabetes and No Diabetes", 
       x = NULL, 
       y = "Proportion")



target_proportions <- es_diab %>%
  count(target) %>%
  mutate(Prop = n / sum(n))

ggplot(target_proportions, aes(x = "", y = Prop, fill = target)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = "Proportion of Diabetes and No Diabetes",
    x = NULL,
    y = NULL
  ) +
  theme_void() +
  theme(legend.position = "right")
```

## Decision Tree

### Regular Train/Test Split + No Upsampling

```{r}
#| label: decision tree - cross validation
#| eval: false

set.seed(8)
data_split <- initial_split(es_diab, prop = 0.75, strata = target)
train <- training(data_split)
test <- testing(data_split)

es_diab_cv <- vfold_cv(train, v = 10)

recipe_tree <- recipe(target ~ ., 
                   data = train) 

tree_mod <- decision_tree(
  cost_complexity = tune(),
  tree_depth = tune()
) %>%
  set_mode("classification") %>%
  set_engine("rpart")

tree_wflow <- workflow() %>%
  add_recipe(recipe_tree) %>%
  add_model(tree_mod)

tree_grid <- grid_regular(
  cost_complexity(range = c(0.001, 0.1)),
  tree_depth(range = c(1, 20)),
  levels = 10
)

cv_results <- tune_grid(
  tree_wflow,
  resamples = es_diab_cv,
  grid = tree_grid,
  metrics = metric_set(roc_auc, accuracy, sensitivity)
)

metrics <- collect_metrics(cv_results)

metrics %>%
    filter(.metric == "roc_auc") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "accuracy") %>%
    arrange(desc(mean))

metrics %>%
    filter(.metric == "sensitivity") %>%
    arrange(desc(mean))
```

```{r}
#| label: decision tree - test set metrics
#| eval: false

dt_mod <- decision_tree(
  cost_complexity = 1.002305,
  tree_depth = 3
) %>%
  set_mode("classification") %>%
  set_engine("rpart")

dt_wflow <- workflow() %>%
  add_recipe(recipe_tree) %>%
  add_model(dt_mod)

dt_fit <- dt_wflow %>%
  fit(data = train)

test_set <- test %>%
  mutate(
    dt_pred_prob = predict(dt_fit, new_data = test, type = "prob")$.pred_diabetes,
    dt_pred_class = predict(dt_fit, new_data = test, type = "class")$.pred_class
  )

test_metrics <- metric_set(accuracy, roc_auc, sensitivity)

metrics_result <- test_metrics(
  data = test_set,
  truth = target,
  estimate = dt_pred_class,
  dt_pred_prob  
)

metrics_result
```

```{r}
#| label: decision tree plot (regular)
#| eval: false

recipe_tree <- recipe(target ~ ., 
                   data = es_diab) 

mod_dt <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

wflow_dt <- workflow() %>%
  add_recipe(recipe_tree) %>%
  add_model(mod_dt)

fit_dt <- wflow_dt %>%
  fit(es_diab)

fitted_dt <- fit_dt %>% 
  extract_fit_parsnip()

rpart.plot(fitted_dt$fit, roundint = FALSE)
```

### Stratified Test/Train Split + Upsampling

```{r}
#| label: decision tree with strat split and upsampling - cross validation
#| eval: false

es_diab <- es_diab %>%
  mutate(strata = paste(target, Gender, sep = "_"))

set.seed(8)
data_split_s <- initial_split(es_diab, prop = 0.75, strata = strata)

train_s <- training(data_split_s)
test_s <- testing(data_split_s)

train_s <- train_s %>% select(-strata)
test_s <- test_s %>% select(-strata)

es_diab_cv_s <- vfold_cv(train_s, v = 10)

balanced_recipe <- recipe(target ~ ., data = train_s) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_upsample(target, over_ratio = 1)

tree_mod <- decision_tree(
  cost_complexity = tune(),
  tree_depth = tune()
) %>%
  set_mode("classification") %>%
  set_engine("rpart")

tree_wflow_s <- workflow() %>%
  add_recipe(balanced_recipe) %>%
  add_model(tree_mod)

tree_grid <- grid_regular(
  cost_complexity(range = c(0.001, 0.1)),
  tree_depth(range = c(1, 20)),
  levels = 10
)

cv_results_s <- tune_grid(
  tree_wflow_s,
  resamples = es_diab_cv_s,
  grid = tree_grid,
  metrics = metric_set(roc_auc, accuracy, sensitivity)
)

metrics_s <- collect_metrics(cv_results_s)

metrics_s %>%
  filter(.metric == "roc_auc") %>%
  arrange(desc(mean))

metrics_s %>%
  filter(.metric == "accuracy") %>%
  arrange(desc(mean))

metrics_s %>%
  filter(.metric == "sensitivity") %>%
  arrange(desc(mean))
```

```{r}
#| label: decision tree with strat split and upsampling - test set metrics
#| eval: false

dt_mod <- decision_tree(
  cost_complexity = 1.002305,
  tree_depth = 3
) %>%
  set_mode("classification") %>%
  set_engine("rpart")

dt_wflow_s <- workflow() %>%
  add_recipe(balanced_recipe) %>%
  add_model(dt_mod)

dt_fit_s <- dt_wflow_s %>%
  fit(data = train_s)

test_set_s <- test_s %>%
  mutate(
    dt_pred_prob = predict(dt_fit_s, new_data = test_s, type = "prob")$.pred_diabetes,
    dt_pred_class = predict(dt_fit_s, new_data = test_s, type = "class")$.pred_class
  )

test_metrics <- metric_set(accuracy, roc_auc, sensitivity)

metrics_result_s <- test_metrics(
  data = test_set_s,
  truth = target,
  estimate = dt_pred_class,
  dt_pred_prob  
)

metrics_result_s
```

## Logistic Regression with LASSO

### Regular Train/Test Split + No Upsampling

```{r}
#| label: log reg with lasso - cross validation

set.seed(8)
data_split <- initial_split(es_diab, prop = 0.75, strata = target)
train <- training(data_split)
test <- testing(data_split)

es_diab_cv <- vfold_cv(train, v = 10)

recipe_train <- recipe(target ~ ., 
                   data = train) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors())

lasso_mod <- logistic_reg(
  penalty = tune(),
  mixture = 1
) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

lasso_wflow <- workflow() %>%
  add_recipe(recipe_train) %>%
  add_model(lasso_mod)

lasso_grid <- grid_regular(
  penalty(),
  levels = 10
)

cv_results_lasso <- tune_grid(
  lasso_wflow,
  resamples = es_diab_cv,
  grid = lasso_grid,
  metrics = metric_set(roc_auc, accuracy, sensitivity)
)

metrics_lasso <- collect_metrics(cv_results_lasso)

metrics_lasso %>%
    filter(.metric == "roc_auc") %>%
    arrange(desc(mean))

metrics_lasso %>%
    filter(.metric == "accuracy") %>%
    arrange(desc(mean))

metrics_lasso %>%
    filter(.metric == "sensitivity") %>%
    arrange(desc(mean))
```

```{r}
#| label: log reg with lasso - test set metrics

lasso_mod_final <- logistic_reg(
  penalty = 0.0004641589,
  mixture = 1
) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

lasso_wflow_final <- workflow() %>%
  add_recipe(recipe_train) %>%
  add_model(lasso_mod_final)

lasso_fit <- lasso_wflow_final %>%
  fit(data = train)

test_set <- test %>%
  mutate(
    pred_prob = predict(lasso_fit, new_data = test, type = "prob")$.pred_diabetes,
    pred_class = predict(lasso_fit, new_data = test, type = "class")$.pred_class
  )

test_metrics <- metric_set(accuracy, roc_auc, sensitivity)

metrics_result <- test_metrics(
  data = test_set,
  truth = target,
  estimate = pred_class,
  pred_prob  
)

metrics_result
```

```{r}
grouped_metrics_result <- test_set %>%
  group_by(Gender) %>%
  summarise(
    accuracy = accuracy_vec(truth = target, estimate = pred_class),
    roc_auc = if (n_distinct(target) > 1) {
      roc_auc_vec(truth = target, estimate = pred_prob)
    } else {
      NA_real_
    },
    sensitivity = sens_vec(truth = target, estimate = pred_class),
    .groups = "drop"  
  )

grouped_metrics_result
```

```{r}
lasso_fit %>% 
  extract_fit_parsnip() %>% 
  tidy() 

lasso_fit %>%
  extract_fit_parsnip() %>%
  tidy() %>%
  mutate(abs_estimate = abs(estimate)) %>%
  arrange(desc(abs_estimate))
```

### Stratified Test/Train Split + Upsampling

```{r}
#| label: log reg with lasso with strat split and upsampling - cross validation
#| eval: false

es_diab <- es_diab %>%
  mutate(strata = paste(target, Gender, sep = "_"))

set.seed(8)
data_split_s <- initial_split(es_diab, prop = 0.75, strata = strata)

train_s <- training(data_split_s)
test_s <- testing(data_split_s)

train_s <- train_s %>% select(-strata)
test_s <- test_s %>% select(-strata)

es_diab_cv_s <- vfold_cv(train_s, v = 10)

balanced_recipe <- recipe(target ~ ., data = train_s) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_upsample(target, over_ratio = 1)

lasso_mod <- logistic_reg(
  penalty = tune(),
  mixture = 1
) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

lasso_wflow <- workflow() %>%
  add_recipe(balanced_recipe) %>%
  add_model(lasso_mod)

lasso_grid <- grid_regular(
  penalty(),
  levels = 10
)

cv_results_lasso <- tune_grid(
  lasso_wflow,
  resamples = es_diab_cv,
  grid = lasso_grid,
  metrics = metric_set(roc_auc, accuracy, sensitivity)
)

metrics_lasso <- collect_metrics(cv_results_lasso)

metrics_lasso %>%
    filter(.metric == "roc_auc") %>%
    arrange(desc(mean))

metrics_lasso %>%
    filter(.metric == "accuracy") %>%
    arrange(desc(mean))

metrics_lasso %>%
    filter(.metric == "sensitivity") %>%
    arrange(desc(mean))
```

```{r}
#| label: log reg with lasso with strat split and upsampling - test set metrics

lasso_mod_final <- logistic_reg(
  penalty = 0.005994843,
  mixture = 1
) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

lasso_wflow_final <- workflow() %>%
  add_recipe(balanced_recipe) %>%
  add_model(lasso_mod_final)

lasso_fit <- lasso_wflow_final %>%
  fit(data = train)

test_set <- test %>%
  mutate(
    pred_prob = predict(lasso_fit, new_data = test, type = "prob")$.pred_diabetes,
    pred_class = predict(lasso_fit, new_data = test, type = "class")$.pred_class
  )

test_metrics <- metric_set(accuracy, roc_auc, sensitivity)

metrics_result <- test_metrics(
  data = test_set,
  truth = target,
  estimate = pred_class,
  pred_prob  
)

metrics_result
```

```{r}
grouped_metrics_result <- test_set %>%
  group_by(Gender) %>%
  summarise(
    accuracy = accuracy_vec(truth = target, estimate = pred_class),
    roc_auc = if (n_distinct(target) > 1) {
      roc_auc_vec(truth = target, estimate = pred_prob)
    } else {
      NA_real_
    },
    sensitivity = sens_vec(truth = target, estimate = pred_class),
    .groups = "drop"  
  )

grouped_metrics_result
```
